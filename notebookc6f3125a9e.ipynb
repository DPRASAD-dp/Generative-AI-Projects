{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82253,"databundleVersionId":8965849,"sourceType":"competition"},{"sourceId":8810254,"sourceType":"datasetVersion","datasetId":5299242},{"sourceId":185900493,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"****EDA Using ydata_profiling***","metadata":{}},{"cell_type":"code","source":"# Make the necessary imports\nimport pandas as pd\nfrom ydata_profiling import ProfileReport\n\n# Load the data\ndf = pd.read_csv(\"/kaggle/input/train-dataset/train.csv\",na_values = \"\\\\N\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:52:02.080703Z","iopub.execute_input":"2024-06-29T04:52:02.081143Z","iopub.status.idle":"2024-06-29T04:52:46.143521Z","shell.execute_reply.started":"2024-06-29T04:52:02.081106Z","shell.execute_reply":"2024-06-29T04:52:46.142308Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2379422059.py:6: DtypeWarning: Columns (15,23,37,47) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/train-dataset/train.csv\",na_values = \"\\\\N\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate the report\nprofile = ProfileReport(df,title=\"F1 Racer Profile\")\n\n# Save the report to .html\nprofile.to_file(\"f1racer_report.html\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the analysis and the visualisaation is in the f1racer_report.html file","metadata":{}},{"cell_type":"markdown","source":"Handling missing values","metadata":{}},{"cell_type":"code","source":"df.head(15)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:17:41.748307Z","iopub.execute_input":"2024-06-29T03:17:41.748751Z","iopub.status.idle":"2024-06-29T03:17:41.785987Z","shell.execute_reply.started":"2024-06-29T03:17:41.748716Z","shell.execute_reply":"2024-06-29T03:17:41.784671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:12:18.590888Z","iopub.execute_input":"2024-06-29T03:12:18.591331Z","iopub.status.idle":"2024-06-29T03:12:24.153586Z","shell.execute_reply.started":"2024-06-29T03:12:18.591297Z","shell.execute_reply":"2024-06-29T03:12:24.152106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:54:40.931271Z","iopub.execute_input":"2024-06-29T04:54:40.931729Z","iopub.status.idle":"2024-06-29T04:54:40.954806Z","shell.execute_reply.started":"2024-06-29T04:54:40.931690Z","shell.execute_reply":"2024-06-29T04:54:40.953552Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2830101 entries, 0 to 2830100\nData columns (total 46 columns):\n #   Column                  Dtype  \n---  ------                  -----  \n 0   resultId                int64  \n 1   racerId                 int64  \n 2   driverId                int64  \n 3   constructorId           int64  \n 4   number                  float64\n 5   grid                    int64  \n 6   position_x              float64\n 7   positionText_x          object \n 8   positionOrder           int64  \n 9   points                  float64\n 10  laps                    int64  \n 11  time_x                  object \n 12  timetaken_in_millisec   float64\n 13  fastestLap              float64\n 14  rank                    float64\n 15  fastestLapTime          object \n 16  max_speed               float64\n 17  statusId                int64  \n 18  year                    int64  \n 19  round                   int64  \n 20  circuitId               int64  \n 21  grand_prix              object \n 22  date                    object \n 23  time_y                  object \n 24  url_x                   object \n 25  driverRef               object \n 26  driver_num              float64\n 27  driver_code             object \n 28  forename                object \n 29  surname                 object \n 30  dob                     object \n 31  nationality             object \n 32  url_y                   object \n 33  driverStandingsId       int64  \n 34  raceId_y                int64  \n 35  points_y                float64\n 36  position                int64  \n 37  positionText_y          object \n 38  wins                    int64  \n 39  constructorRef          object \n 40  company                 object \n 41  nationality_y           object \n 42  url                     object \n 43  status                  object \n 44  result_driver_standing  int64  \n 45  rank_missing            bool   \ndtypes: bool(1), float64(9), int64(16), object(20)\nmemory usage: 974.3+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\n# Drop columns with 100% missing values\ncols_to_drop = ['fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time']\ndf.drop(columns=cols_to_drop, inplace=True)\n\n# Mean/Median imputation for numerical columns\ndf['position_x'].fillna(df['position_x'].mean(), inplace=True)\ndf['timetaken_in_millisec'].fillna(df['timetaken_in_millisec'].median(), inplace=True)\ndf['max_speed'].fillna(df['max_speed'].mean(), inplace=True)\n\n# Mode imputation for categorical columns\ndf['driver_code'].fillna(df['driver_code'].mode()[0], inplace=True)\n\n# Forward fill for time series columns\ndf['time_x'].fillna(method='ffill', inplace=True)\ndf['time_y'].fillna(method='ffill', inplace=True)\n\n# Create a flag for missing values in 'rank' and then fill with the median\ndf['rank_missing'] = df['rank'].isnull()\ndf['rank'].fillna(df['rank'].median(), inplace=True)\n\n# Predictive imputation can be done using models (not shown here for simplicity)\n\nprint(df.isnull().sum())  # Check remaining missing values\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:53:00.965925Z","iopub.execute_input":"2024-06-29T04:53:00.966340Z","iopub.status.idle":"2024-06-29T04:53:09.604250Z","shell.execute_reply.started":"2024-06-29T04:53:00.966309Z","shell.execute_reply":"2024-06-29T04:53:09.602891Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/742730725.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['position_x'].fillna(df['position_x'].mean(), inplace=True)\n/tmp/ipykernel_33/742730725.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['timetaken_in_millisec'].fillna(df['timetaken_in_millisec'].median(), inplace=True)\n/tmp/ipykernel_33/742730725.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['max_speed'].fillna(df['max_speed'].mean(), inplace=True)\n/tmp/ipykernel_33/742730725.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['driver_code'].fillna(df['driver_code'].mode()[0], inplace=True)\n/tmp/ipykernel_33/742730725.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['time_x'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_33/742730725.py:17: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df['time_x'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_33/742730725.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['time_y'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_33/742730725.py:18: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df['time_y'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_33/742730725.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['rank'].fillna(df['rank'].median(), inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"resultId                        0\nracerId                         0\ndriverId                        0\nconstructorId                   0\nnumber                        160\ngrid                            0\nposition_x                      0\npositionText_x                  0\npositionOrder                   0\npoints                          0\nlaps                            0\ntime_x                          0\ntimetaken_in_millisec           0\nfastestLap                2112010\nrank                            0\nfastestLapTime            2112010\nmax_speed                       0\nstatusId                        0\nyear                            0\nround                           0\ncircuitId                       0\ngrand_prix                      0\ndate                            0\ntime_y                    2150026\nurl_x                           0\ndriverRef                       0\ndriver_num                2354922\ndriver_code                     0\nforename                        0\nsurname                         0\ndob                             0\nnationality                     0\nurl_y                           0\ndriverStandingsId               0\nraceId_y                        0\npoints_y                        0\nposition                        0\npositionText_y                  0\nwins                            0\nconstructorRef                  0\ncompany                         0\nnationality_y                   0\nurl                             0\nstatus                          0\nresult_driver_standing          0\nrank_missing                    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\n\n# Handle `fastestLap` and `fastestLapTime`\n# Example: Fill with a default value -1\ndf['fastestLap'].fillna(-1, inplace=True)\ndf['fastestLapTime'].fillna('00:00:00', inplace=True)  # Assuming the time format is HH:MM:SS\n\n# Handle `time_y` using forward fill as an example\ndf['time_y'].fillna(method='ffill', inplace=True)\n\n# Handle `driver_num` using mode imputation as an example\ndf['driver_num'].fillna(df['driver_num'].mode()[0], inplace=True)\n\nprint(df.isnull().sum())  # Check remaining missing values\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:53:25.031667Z","iopub.execute_input":"2024-06-29T04:53:25.032194Z","iopub.status.idle":"2024-06-29T04:53:31.959312Z","shell.execute_reply.started":"2024-06-29T04:53:25.032157Z","shell.execute_reply":"2024-06-29T04:53:31.958153Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/973991952.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['fastestLap'].fillna(-1, inplace=True)\n/tmp/ipykernel_33/973991952.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['fastestLapTime'].fillna('00:00:00', inplace=True)  # Assuming the time format is HH:MM:SS\n/tmp/ipykernel_33/973991952.py:11: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df['time_y'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_33/973991952.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['driver_num'].fillna(df['driver_num'].mode()[0], inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"resultId                        0\nracerId                         0\ndriverId                        0\nconstructorId                   0\nnumber                        160\ngrid                            0\nposition_x                      0\npositionText_x                  0\npositionOrder                   0\npoints                          0\nlaps                            0\ntime_x                          0\ntimetaken_in_millisec           0\nfastestLap                      0\nrank                            0\nfastestLapTime                  0\nmax_speed                       0\nstatusId                        0\nyear                            0\nround                           0\ncircuitId                       0\ngrand_prix                      0\ndate                            0\ntime_y                    2150026\nurl_x                           0\ndriverRef                       0\ndriver_num                      0\ndriver_code                     0\nforename                        0\nsurname                         0\ndob                             0\nnationality                     0\nurl_y                           0\ndriverStandingsId               0\nraceId_y                        0\npoints_y                        0\nposition                        0\npositionText_y                  0\nwins                            0\nconstructorRef                  0\ncompany                         0\nnationality_y                   0\nurl                             0\nstatus                          0\nresult_driver_standing          0\nrank_missing                    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Handle `time_y` using a combination of forward fill and backward fill\ndf['time_y'].fillna(method='ffill', inplace=True)\ndf['time_y'].fillna(method='bfill', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:53:37.388291Z","iopub.execute_input":"2024-06-29T04:53:37.388708Z","iopub.status.idle":"2024-06-29T04:53:38.454079Z","shell.execute_reply.started":"2024-06-29T04:53:37.388674Z","shell.execute_reply":"2024-06-29T04:53:38.453071Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/72336672.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df['time_y'].fillna(method='ffill', inplace=True)\n/tmp/ipykernel_33/72336672.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  df['time_y'].fillna(method='bfill', inplace=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:54:57.447935Z","iopub.execute_input":"2024-06-29T04:54:57.448356Z","iopub.status.idle":"2024-06-29T04:55:03.523751Z","shell.execute_reply.started":"2024-06-29T04:54:57.448321Z","shell.execute_reply":"2024-06-29T04:55:03.522514Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"resultId                    0\nracerId                     0\ndriverId                    0\nconstructorId               0\nnumber                    160\ngrid                        0\nposition_x                  0\npositionText_x              0\npositionOrder               0\npoints                      0\nlaps                        0\ntime_x                      0\ntimetaken_in_millisec       0\nfastestLap                  0\nrank                        0\nfastestLapTime              0\nmax_speed                   0\nstatusId                    0\nyear                        0\nround                       0\ncircuitId                   0\ngrand_prix                  0\ndate                        0\ntime_y                      0\nurl_x                       0\ndriverRef                   0\ndriver_num                  0\ndriver_code                 0\nforename                    0\nsurname                     0\ndob                         0\nnationality                 0\nurl_y                       0\ndriverStandingsId           0\nraceId_y                    0\npoints_y                    0\nposition                    0\npositionText_y              0\nwins                        0\nconstructorRef              0\ncompany                     0\nnationality_y               0\nurl                         0\nstatus                      0\nresult_driver_standing      0\nrank_missing                0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df['number'].fillna(df['number'].mode()[0], inplace=True)\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:55:08.187948Z","iopub.execute_input":"2024-06-29T04:55:08.188787Z","iopub.status.idle":"2024-06-29T04:55:14.313295Z","shell.execute_reply.started":"2024-06-29T04:55:08.188750Z","shell.execute_reply":"2024-06-29T04:55:14.312171Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/138817072.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df['number'].fillna(df['number'].mode()[0], inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"resultId                  0\nracerId                   0\ndriverId                  0\nconstructorId             0\nnumber                    0\ngrid                      0\nposition_x                0\npositionText_x            0\npositionOrder             0\npoints                    0\nlaps                      0\ntime_x                    0\ntimetaken_in_millisec     0\nfastestLap                0\nrank                      0\nfastestLapTime            0\nmax_speed                 0\nstatusId                  0\nyear                      0\nround                     0\ncircuitId                 0\ngrand_prix                0\ndate                      0\ntime_y                    0\nurl_x                     0\ndriverRef                 0\ndriver_num                0\ndriver_code               0\nforename                  0\nsurname                   0\ndob                       0\nnationality               0\nurl_y                     0\ndriverStandingsId         0\nraceId_y                  0\npoints_y                  0\nposition                  0\npositionText_y            0\nwins                      0\nconstructorRef            0\ncompany                   0\nnationality_y             0\nurl                       0\nstatus                    0\nresult_driver_standing    0\nrank_missing              0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Handling duplicate values","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\n\n# Identify all duplicate rows\nduplicates = df.duplicated()\nprint(duplicates.sum())  # Count of duplicate rows\nprint(df[duplicates])","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:21:49.163081Z","iopub.execute_input":"2024-06-29T03:21:49.164162Z","iopub.status.idle":"2024-06-29T03:21:57.643966Z","shell.execute_reply.started":"2024-06-29T03:21:49.164123Z","shell.execute_reply":"2024-06-29T03:21:57.642564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No duplicate rows found","metadata":{}},{"cell_type":"markdown","source":"Removing unnecessary columns","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\ncols_to_drop = [\n    'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time',\n    'quali_date', 'quali_time', 'sprint_date', 'sprint_time',\n    'url_x', 'url_y', 'url', 'time_y', 'driver_num', 'raceId_y', 'positionText_x', 'positionText_y', 'driverRef',\n    'fastestLap', 'fastestLapTime'\n]\n\n# Check which columns actually exist in the DataFrame\nexisting_cols_to_drop = [col for col in cols_to_drop if col in df.columns]\n\n# Drop only the existing columns\ndf.drop(columns=existing_cols_to_drop, inplace=True)\n\n# Print the remaining columns to verify\nprint(df.columns)\n\n# Check for remaining missing values\nprint(df.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:55:23.914596Z","iopub.execute_input":"2024-06-29T04:55:23.915010Z","iopub.status.idle":"2024-06-29T04:55:28.364347Z","shell.execute_reply.started":"2024-06-29T04:55:23.914980Z","shell.execute_reply":"2024-06-29T04:55:28.362945Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Index(['resultId', 'racerId', 'driverId', 'constructorId', 'number', 'grid',\n       'position_x', 'positionOrder', 'points', 'laps', 'time_x',\n       'timetaken_in_millisec', 'rank', 'max_speed', 'statusId', 'year',\n       'round', 'circuitId', 'grand_prix', 'date', 'driver_code', 'forename',\n       'surname', 'dob', 'nationality', 'driverStandingsId', 'points_y',\n       'position', 'wins', 'constructorRef', 'company', 'nationality_y',\n       'status', 'result_driver_standing', 'rank_missing'],\n      dtype='object')\nresultId                  0\nracerId                   0\ndriverId                  0\nconstructorId             0\nnumber                    0\ngrid                      0\nposition_x                0\npositionOrder             0\npoints                    0\nlaps                      0\ntime_x                    0\ntimetaken_in_millisec     0\nrank                      0\nmax_speed                 0\nstatusId                  0\nyear                      0\nround                     0\ncircuitId                 0\ngrand_prix                0\ndate                      0\ndriver_code               0\nforename                  0\nsurname                   0\ndob                       0\nnationality               0\ndriverStandingsId         0\npoints_y                  0\nposition                  0\nwins                      0\nconstructorRef            0\ncompany                   0\nnationality_y             0\nstatus                    0\nresult_driver_standing    0\nrank_missing              0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T03:30:38.098160Z","iopub.execute_input":"2024-06-29T03:30:38.098589Z","iopub.status.idle":"2024-06-29T03:30:39.784727Z","shell.execute_reply.started":"2024-06-29T03:30:38.098557Z","shell.execute_reply":"2024-06-29T03:30:39.783583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Handling the outliers using IQR technique","metadata":{}},{"cell_type":"code","source":"# Get list of numerical and categorical columns\nnumerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_columns = df.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n\nprint(\"Numerical columns:\", numerical_columns)\nprint(\"Categorical columns:\", categorical_columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:55:44.758120Z","iopub.execute_input":"2024-06-29T04:55:44.758503Z","iopub.status.idle":"2024-06-29T04:55:45.222882Z","shell.execute_reply.started":"2024-06-29T04:55:44.758474Z","shell.execute_reply":"2024-06-29T04:55:45.221800Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Numerical columns: ['resultId', 'racerId', 'driverId', 'constructorId', 'number', 'grid', 'position_x', 'positionOrder', 'points', 'laps', 'timetaken_in_millisec', 'rank', 'max_speed', 'statusId', 'year', 'round', 'circuitId', 'driverStandingsId', 'points_y', 'position', 'wins', 'result_driver_standing']\nCategorical columns: ['time_x', 'grand_prix', 'date', 'driver_code', 'forename', 'surname', 'dob', 'nationality', 'constructorRef', 'company', 'nationality_y', 'status', 'rank_missing']\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame with numerical columns as identified\n\n# List of numerical columns\nnumerical_columns = [\n    'resultId', 'racerId', 'driverId', 'constructorId', 'number', 'grid', 'position_x', 'positionOrder', 'points', 'laps', 'timetaken_in_millisec', 'rank', 'max_speed', 'statusId', 'year', 'round', 'circuitId', 'driverStandingsId', 'points_y', 'position', 'wins', 'result_driver_standing'\n]\n\n# Calculate Q1, Q3, and IQR for each numerical column\nQ1 = df[numerical_columns].quantile(0.25)\nQ3 = df[numerical_columns].quantile(0.75)\nIQR = Q3 - Q1\n\n# Define lower and upper bounds to identify outliers\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Handling outliers: Replace or remove\nfor col in numerical_columns:\n    # Replace outliers with the nearest non-outlier value\n    df[col] = df[col].mask(df[col] < lower_bound[col], df[col].quantile(0.05))\n    df[col] = df[col].mask(df[col] > upper_bound[col], df[col].quantile(0.95))\n\n# Print the updated DataFrame to verify changes\nprint(df.describe())\n\n# Optionally, you can save the cleaned DataFrame to a CSV file\ndf.to_csv('cleaned_race_data_with_outliers_handled.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:56:17.112194Z","iopub.execute_input":"2024-06-29T04:56:17.113093Z","iopub.status.idle":"2024-06-29T04:57:34.867247Z","shell.execute_reply.started":"2024-06-29T04:56:17.113049Z","shell.execute_reply":"2024-06-29T04:57:34.865945Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"           resultId       racerId      driverId  constructorId        number  \\\ncount  2.830101e+06  2.830101e+06  2.830101e+06   2.830101e+06  2.830101e+06   \nmean   9.787394e+03  3.963803e+02  1.271127e+02   3.497251e+01  1.309785e+01   \nstd    6.597046e+03  2.523813e+02  1.254326e+02   4.981984e+01  9.220298e+00   \nmin    1.000000e+00  1.000000e+00  1.000000e+00   1.000000e+00  0.000000e+00   \n25%    3.896000e+03  1.810000e+02  2.200000e+01   6.000000e+00  5.000000e+00   \n50%    9.179000e+03  3.730000e+02  9.500000e+01   1.700000e+01  1.100000e+01   \n75%    1.487100e+04  5.720000e+02  1.850000e+02   3.400000e+01  2.000000e+01   \nmax    2.430500e+04  8.990000e+02  4.560000e+02   1.700000e+02  4.200000e+01   \n\n               grid    position_x  positionOrder        points          laps  \\\ncount  2.830101e+06  2.830101e+06   2.830101e+06  2.830101e+06  2.830101e+06   \nmean   9.924075e+00  6.801812e+00   1.165541e+01  1.956195e+00  4.656398e+01   \nstd    6.731309e+00  3.453843e+00   7.616827e+00  3.289026e+00  2.512447e+01   \nmin    0.000000e+00  1.000000e+00   1.000000e+00  0.000000e+00  0.000000e+00   \n25%    4.000000e+00  5.000000e+00   5.000000e+00  0.000000e+00  2.700000e+01   \n50%    9.000000e+00  6.753799e+00   1.100000e+01  0.000000e+00  5.300000e+01   \n75%    1.500000e+01  7.000000e+00   1.800000e+01  3.000000e+00  6.700000e+01   \nmax    3.100000e+01  1.400000e+01   3.700000e+01  1.000000e+01  1.270000e+02   \n\n       ...     max_speed      statusId          year         round  \\\ncount  ...  2.830101e+06  2.830101e+06  2.830101e+06  2.830101e+06   \nmean   ...  2.036574e+02  1.552548e+01  1.991024e+03  8.455734e+00   \nstd    ...  7.166453e+00  2.473311e+01  1.508482e+01  4.803080e+00   \nmin    ...  1.905750e+02  1.000000e+00  1.950000e+03  1.000000e+00   \n25%    ...  2.029434e+02  1.000000e+00  1.980000e+03  4.000000e+00   \n50%    ...  2.029434e+02  6.000000e+00  1.992000e+03  8.000000e+00   \n75%    ...  2.029434e+02  1.200000e+01  2.004000e+03  1.200000e+01   \nmax    ...  2.187000e+02  8.100000e+01  2.013000e+03  2.000000e+01   \n\n          circuitId  driverStandingsId      points_y      position  \\\ncount  2.830101e+06       2.830101e+06  2.830101e+06  2.830101e+06   \nmean   2.052825e+01       3.466954e+04  1.739093e+01  1.196525e+01   \nstd    1.494545e+01       2.380309e+04  2.618544e+01  8.399548e+00   \nmin    1.000000e+00       1.000000e+00  0.000000e+00  1.000000e+00   \n25%    9.000000e+00       1.271200e+04  0.000000e+00  5.000000e+00   \n50%    1.700000e+01       2.173600e+04  6.000000e+00  1.000000e+01   \n75%    3.000000e+01       5.808600e+04  2.100000e+01  1.700000e+01   \nmax    6.100000e+01       7.218700e+04  8.700000e+01  3.500000e+01   \n\n               wins  result_driver_standing  \ncount  2.830101e+06            2.830101e+06  \nmean   6.198086e-01            4.021545e+08  \nstd    1.214604e+00            4.346233e+08  \nmin    0.000000e+00            1.000000e+00  \n25%    0.000000e+00            5.169145e+07  \n50%    0.000000e+00            1.982056e+08  \n75%    0.000000e+00            7.733493e+08  \nmax    3.000000e+00            1.698907e+09  \n\n[8 rows x 22 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"unique_values = df['time_x'].unique()\n\n# Print the unique values\nprint(unique_values)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T05:38:40.954383Z","iopub.execute_input":"2024-06-29T05:38:40.955203Z","iopub.status.idle":"2024-06-29T05:38:40.961965Z","shell.execute_reply.started":"2024-06-29T05:38:40.955163Z","shell.execute_reply":"2024-06-29T05:38:40.960703Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"['2:13:23.6' '+2.6' '+52.0' '+1:36.853' '1:32:36.300' '+10.452']\n","output_type":"stream"}]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/working/cleaned_race_data_with_outliers_handled.csv\")\ndf1.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:31:19.976166Z","iopub.execute_input":"2024-06-29T06:31:19.976494Z","iopub.status.idle":"2024-06-29T06:31:20.120943Z","shell.execute_reply.started":"2024-06-29T06:31:19.976469Z","shell.execute_reply":"2024-06-29T06:31:20.119911Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/cleaned_race_data_with_outliers_handled.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df1\u001b[38;5;241m.\u001b[39minfo()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/cleaned_race_data_with_outliers_handled.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/cleaned_race_data_with_outliers_handled.csv'","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n\ntrain_df = pd.read_csv(\"/kaggle/input/myyydata/cleaned_race_data_with_outliers_handled.csv\")\nval_df = pd.read_csv(\"/kaggle/input/mydataset/validation/validation.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/mydataset/test/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:42:42.921592Z","iopub.execute_input":"2024-06-29T06:42:42.921940Z","iopub.status.idle":"2024-06-29T06:43:09.919409Z","shell.execute_reply.started":"2024-06-29T06:42:42.921914Z","shell.execute_reply":"2024-06-29T06:43:09.918574Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1405664855.py:16: DtypeWarning: Columns (13,16,36) have mixed types. Specify dtype option on import or set low_memory=False.\n  val_df = pd.read_csv(\"/kaggle/input/mydataset/validation/validation.csv\")\n/tmp/ipykernel_34/1405664855.py:17: DtypeWarning: Columns (13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n  test_df = pd.read_csv(\"/kaggle/input/mydataset/test/test.csv\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/myyydata/cleaned_race_data_with_outliers_handled.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:43:44.987054Z","iopub.execute_input":"2024-06-29T06:43:44.987439Z","iopub.status.idle":"2024-06-29T06:43:57.947800Z","shell.execute_reply.started":"2024-06-29T06:43:44.987411Z","shell.execute_reply":"2024-06-29T06:43:57.946750Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define feature columns and target variable\nX_train = train_df.drop(columns=['position'])\ny_train = train_df['position']\n\nX_val = val_df.drop(columns=['position'])\ny_val = val_df['position']\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:44:02.874503Z","iopub.execute_input":"2024-06-29T06:44:02.874844Z","iopub.status.idle":"2024-06-29T06:44:03.515607Z","shell.execute_reply.started":"2024-06-29T06:44:02.874818Z","shell.execute_reply":"2024-06-29T06:44:03.514777Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define numerical and categorical columns\nnumerical_cols = [\"points\",\"timetaken_in_millisec\",\"max_speed\",\"points_y\",\"wins\"]\ncategorical_cols = X_train.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n\n# Define the preprocessing steps for numerical and categorical data\nnumerical_transformer = StandardScaler()\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n# Create a ColumnTransformer to apply the preprocessing\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:44:06.817378Z","iopub.execute_input":"2024-06-29T06:44:06.817720Z","iopub.status.idle":"2024-06-29T06:44:07.193964Z","shell.execute_reply.started":"2024-06-29T06:44:06.817695Z","shell.execute_reply":"2024-06-29T06:44:07.193185Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Assuming `preprocessor`, `X_train`, `y_train`, `X_val`, `y_val` are defined and prepared appropriately\n\n# Define Linear Regression model\nlinear_reg = LinearRegression()\n\n# Dictionary to store the best Linear Regression model and its performance\nbest_linear_model = None\nbest_linear_score = None\n\nprint(\"Training Linear Regression...\")\n\n# Create a pipeline that combines the preprocessor with Linear Regression\nlinear_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', linear_reg)\n])\n\n# Fit the model\nlinear_pipeline.fit(X_train, y_train)\n\n# Evaluate on the validation set\nprint(\"Evaluating Linear Regression on the validation set...\")\ny_val_pred_linear = linear_pipeline.predict(X_val)\nrmse_val_linear = np.sqrt(mean_squared_error(y_val, y_val_pred_linear))\nprint(f\"RMSE on validation set for Linear Regression: {rmse_val_linear}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-29T06:55:14.309808Z","iopub.execute_input":"2024-06-29T06:55:14.310138Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training Linear Regression...\n","output_type":"stream"}]}]}